* Indexing by Latent Semantic Analysis
* The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge
* word2vec Explained: Deriving Mikolov et al.â€™s Negative-Sampling Word-Embedding Method
* Stability and Generalization
* Adaptive Subgradient Methods for Online Learning and Stochastic Optimization
* The Method of projections for finding the common point of convex sets
* A semismooth newton method for fast, generic convex programming
* SuperMann: A superlinearly convergent algorithm for finding fixed points of nonexpansive operators
* On projection algorithms for solving convex feasibility problems
* Monotone operator methods
* Distributed optimization and statistical learning via the alternating directions method of multipliers
* Line search for averaged operator iteration
* A Convex Optimization Approach to Radiation Treatment Planning with Dose Constraints
* The idea behind Krylov methods
* Densely Connected Convolutional Networks
* Learning from Simulated and Unsupervised Images through Adversarial Training 
* Computational Imaging on the Electric Grid 
* Convexified Convolutional Neural Networks
* Feynman's lecture on quantum computers (https://people.eecs.berkeley.edu/~christos/classics/Feynman.pdf)
* ANDERSON ACCELERATION FOR FIXED-POINT ITERATIONS
* Two Classes of Multisecant Methods for Nonlinear Acceleration
* ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION
* Multi-Period Trading via Convex Optimization (http://stanford.edu/~boyd/papers/cvx_portfolio.html)
* Breaking the Curse of Dimensionality with Convex Neural Networks
* A Tutorial on Bayesian Optimization of
Expensive Cost Functions, with Application to Active User Modeling and
Hierarchical Reinforcement Learning [https://arxiv.org/pdf/1012.2599.pdf]
* https://people.eecs.berkeley.edu/~jshun/thesis.pdf
* A practical guide to CNNs and Fisher Vectors for image instance retrieval
* SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives
* Stochastic Dual Coordinate Ascent Methods for Regularized Loss Minimization
* Accelerating Stochastic Gradient Descent using Predictive Variance Reduction
* http://www.cds.caltech.edu/~doyle/hot/SDPrelaxations.pdf
* Occupy the Cloud: Distributed Computing for the 99% (PyWren)
* Improving Efficiency and Scalability of Sum of Squares Optimization:
Recent Advances and Limitations
* NP-hardness of deciding convexity of quartic polynomials and related problems
* Tractable fitting with convex polynomials via sum-of-squares
* LAGRANGE MULTIPLIERS AND OPTIMALITY
* Mastering the game of Go without human knowledge
* Interior-point methods for optimization (Nemirovski and Todd)
* Convergence rate of incremental aggregated gradient algorithms (Pablo Parrilo)
* Towards Generalization and Simplicity in Continuous Control (kakade)

